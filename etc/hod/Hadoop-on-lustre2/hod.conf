#-*- cfg -*-
# vim: ft=cfg
[Meta]
version=1

[Config]
modules=Hadoop/2.4.0-seagate
master_env=HADOOP_HOME,EBROOTHADOOP,JAVA_HOME
services=resourcemanager.conf,nodemanager.conf,screen.conf
config_writer=hod.config.writer.hadoop_xml
# change the following to a path on the parallel file system.
workdir=/tmp
directories=$workdir/dfs/name,$workdir/dfs/data,$workdir/hadoop-staging

[core-site.xml]
hadoop.tmp.dir=$workdir/tmp
dfs.replication=1
fs.defaultFS=file:///
fs.inmemory.size.mb=200
io.file.buffer.size=4194304 
io.sort.factor=64
io.sort.mb=256

[mapred-site.xml]
mapreduce.framework.name=yarn                                                         
mapreduce.map.memory.mb=4096
mapreduce.reduce.memory.mb=8192
mapreduce.map.java.opts=-Xmx3072m
mapreduce.reduce.java.opts=-Xmx6144m
yarn.app.mapreduce.am.staging-dir=$workdir/hadoop-staging
lustre.dir=$workdir 
hadoop.ln.cmd=/bin/ln 

[yarn-site.xml]
yarn.nodemanager.aux-services=mapreduce_shuffle 
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.maximum-allocation-mb=57344
yarn.nodemanager.minimum-allocation-mb=2048
yarn.nodemanager.resource.memory-mb=57344
yarn.nodemanager.vmem-check-enabled=false
yarn.nodemanager.vmem-pmem-ratio=2.1
yarn.nodemanager.local-dirs=$workdir/$hostname
yarn.resourcemanager.hostname=$masterdataname
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
yarn.scheduler.capacity.allocation.file=capacity-scheduler.xml

[capacity-scheduler.xml]
yarn.scheduler.capacity.root.queues=default
yarn.scheduler.capacity.root.default.capacity=100
yarn.scheduler.capacity.root.default.minimum-user-limit-percent=100
