#-*- cfg -*-
# vim: ft=cfg
[Meta]
version=1

[Config]
modules=Hadoop/2.5.0-cdh5.3.1
master_env=HADOOP_HOME,EBROOTHADOOP,JAVA_HOME
services=resourcemanager.conf,nodemanager.conf,screen.conf
config_writer=hod.config.writer.hadoop_xml
workdir=/user/scratchphanpy/vsc41041/hod
directories=$localworkdir/dfs/name,$localworkdir/dfs/data

[core-site.xml]
hadoop.tmp.dir=$localworkdir/tmp
dfs.replication=1
fs.defaultFS=gpfs:///
fs.gpfs.impl=org.apache.hadoop.fs.gpfs.GeneralParallelFileSystem
fs.AbstractFileSystem.gpfs.impl=org.apache.hadoop.fs.gpfs.GeneralParallelFs
gpfs.mount.dir=/user/scratchphanpy
gpfs.supergroup=vsc41041
dfs.blocksize=268435456
fs.inmemory.size.mb=200
io.file.buffer.size=4194304 
io.sort.factor=64
io.sort.mb=256

[mapred-site.xml]
mapreduce.framework.name=yarn                                                         
mapreduce.map.memory.mb=4096
mapreduce.reduce.memory.mb=8192
mapreduce.map.java.opts=-Xmx3072m
mapreduce.reduce.java.opts=-Xmx6144m
mapreduce.job.working.dir=$localworkdir
# TODO: get thhe gpfs mount stripped off.
yarn.app.mapreduce.am.staging-dir=/vsc41041/$hostname/hadoop-staging 

[yarn-site.xml]
yarn.nodemanager.aux-services=mapreduce_shuffle
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.maximum-allocation-mb=57344
yarn.nodemanager.minimum-allocation-mb=2048
yarn.nodemanager.resource.memory-mb=57344
yarn.nodemanager.vmem-check-enabled=false
yarn.nodemanager.vmem-pmem-ratio=2.1
yarn.nodemanager.local-dirs=$localworkdir/$hostname
yarn.resourcemanager.hostname=$masterdataname
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
yarn.scheduler.capacity.allocation.file=capacity-scheduler.xml

[capacity-scheduler.xml]
yarn.scheduler.capacity.root.queues=default
yarn.scheduler.capacity.root.default.capacity=100
yarn.scheduler.capacity.root.default.minimum-user-limit-percent=100

[log4j.properties]
log4j.logger.org.apache.hadoop=INFO
log4j.logger.org.apache.hadoop.yarn=INFO
# GPFS audit logger
log4j.additivity.org.apache.hadoop.fs.gpfs.GeneralParallelFileSystem.audit=false
log4j.logger.org.apache.hadoop.fs.gpfs.GeneralParallelFileSystem.audit=INFO,NullAppender
